"""
Pipeline å¤šè¿›ç¨‹æ€§èƒ½åˆ†æ

æ·±å…¥åˆ†æå¤šè¿›ç¨‹æ¶æ„ä¸­çš„ç“¶é¢ˆï¼š
1. I/O Worker ç­‰å¾… Detector å“åº”çš„æ—¶é—´
2. Detector å¤„ç† batch çš„æ—¶é—´
3. Queue çš„æ’é˜Ÿå»¶è¿Ÿ
4. å„è¿›ç¨‹çš„å®é™… CPU åˆ©ç”¨æƒ…å†µ
"""

import time
import subprocess
import multiprocessing as mp
from pathlib import Path
from queue import Empty
import numpy as np
import argparse
import os
import json
from dataclasses import dataclass


def probe_video_info(video_path: str) -> dict | None:
    """è·å–è§†é¢‘ä¿¡æ¯"""
    try:
        cmd = [
            "ffprobe",
            "-v", "quiet",
            "-print_format", "json",
            "-show_format",
            "-show_streams",
            video_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0:
            return None
        
        data = json.loads(result.stdout)
        
        video_stream = None
        for stream in data.get('streams', []):
            if stream.get('codec_type') == 'video':
                video_stream = stream
                break
        
        if not video_stream:
            return None
        
        fps_str = video_stream.get('r_frame_rate', '30/1')
        try:
            if '/' in fps_str:
                num, den = fps_str.split('/')
                fps = float(num) / float(den)
            else:
                fps = float(fps_str)
        except:
            fps = 30.0
        
        duration = float(data.get('format', {}).get('duration', 0))
        frame_count = int(video_stream.get('nb_frames', 0))
        if frame_count == 0 and duration > 0:
            frame_count = int(duration * fps)
        
        return {
            'fps': fps,
            'width': int(video_stream.get('width', 0)),
            'height': int(video_stream.get('height', 0)),
            'frame_count': frame_count,
            'duration': duration,
        }
    except Exception as e:
        print(f"Error probing {video_path}: {e}")
        return None


def get_video_files(input_dir: str) -> list[Path]:
    """è·å–è§†é¢‘æ–‡ä»¶"""
    input_path = Path(input_dir)
    videos = []
    for ext in ['.mp4', '.avi', '.mov', '.mkv']:
        videos.extend(input_path.rglob(f"*{ext}"))
    return sorted(videos)


def simulate_io_worker_timing(
    video_path: str,
    sample_interval: float,
    batch_size: int,
    decode_threads: int = 2
) -> dict:
    """
    æ¨¡æ‹Ÿ I/O Worker çš„æ—¶åºï¼Œæµ‹é‡å„é˜¶æ®µè€—æ—¶
    """
    info = probe_video_info(video_path)
    if not info:
        return {'error': 'Cannot probe video'}
    
    fps = info['fps']
    width = info['width']
    height = info['height']
    duration = info['duration']
    total_frames = info['frame_count']
    
    frame_interval = max(1, int(fps * sample_interval))
    frame_size = width * height * 3
    expected_frames = total_frames // frame_interval
    
    # å¯åŠ¨ ffmpeg
    select_filter = f"select='not(mod(n\\,{frame_interval}))'"
    cmd = [
        "ffmpeg",
        "-threads", str(decode_threads),
        "-i", video_path,
        "-vf", select_filter,
        "-vsync", "vfr",
        "-f", "rawvideo",
        "-pix_fmt", "rgb24",
        "-loglevel", "error",
        "-"
    ]
    
    timings = {
        'batch_read_times': [],  # æ¯ä¸ª batch è¯»å–å¸§çš„æ—¶é—´
        'batch_sizes': [],       # æ¯ä¸ª batch å®é™…å¸§æ•°
        'total_frames': 0,
    }
    
    proc = subprocess.Popen(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        bufsize=frame_size * 4
    )
    
    batch_count = 0
    total_frames_read = 0
    
    while True:
        batch_start = time.perf_counter()
        frames_in_batch = 0
        
        for _ in range(batch_size):
            raw_data = proc.stdout.read(frame_size)
            if len(raw_data) != frame_size:
                break
            frames_in_batch += 1
        
        batch_end = time.perf_counter()
        
        if frames_in_batch == 0:
            break
        
        timings['batch_read_times'].append(batch_end - batch_start)
        timings['batch_sizes'].append(frames_in_batch)
        total_frames_read += frames_in_batch
        batch_count += 1
    
    proc.stdout.close()
    proc.wait()
    
    timings['total_frames'] = total_frames_read
    timings['batch_count'] = batch_count
    timings['video_duration'] = duration
    
    return timings


def detector_worker_simulation(
    request_queue: mp.Queue,
    response_queue: mp.Queue,
    stats_queue: mp.Queue,
    model_name: str,
    stop_event: mp.Event,
    detector_id: int
):
    """
    æ¨¡æ‹Ÿ Detector Workerï¼Œè®°å½•å¤„ç†æ—¶é—´
    """
    from ultralytics import YOLO
    
    model = YOLO(model_name)
    
    stats = {
        'batch_inference_times': [],
        'batch_sizes': [],
        'queue_wait_times': [],
        'total_processed': 0,
    }
    
    while not stop_event.is_set():
        wait_start = time.perf_counter()
        try:
            request = request_queue.get(timeout=0.5)
        except Empty:
            continue
        wait_end = time.perf_counter()
        
        if request is None:
            break
        
        request_id, frames, frame_times = request
        stats['queue_wait_times'].append(wait_end - wait_start)
        
        if frames:
            infer_start = time.perf_counter()
            results = model(frames, verbose=False, conf=0.5, classes=[0])
            infer_end = time.perf_counter()
            
            stats['batch_inference_times'].append(infer_end - infer_start)
            stats['batch_sizes'].append(len(frames))
            stats['total_processed'] += len(frames)
            
            frame_results = [(frame_times[i], len(results[i].boxes)) for i in range(len(results))]
            response_queue.put((request_id, frame_results))
        else:
            response_queue.put((request_id, []))
    
    stats_queue.put((detector_id, stats))


def io_worker_simulation(
    video_path: str,
    detection_queue: mp.Queue,
    response_queue: mp.Queue,
    stats_queue: mp.Queue,
    worker_id: int,
    sample_interval: float,
    batch_size: int,
    max_pending: int = 8,
    decode_threads: int = 2
):
    """
    æ¨¡æ‹Ÿ I/O Workerï¼Œè®°å½•å„é˜¶æ®µæ—¶é—´
    """
    info = probe_video_info(video_path)
    if not info:
        stats_queue.put((worker_id, {'error': 'Cannot probe video'}))
        return
    
    fps = info['fps']
    width = info['width']
    height = info['height']
    frame_interval = max(1, int(fps * sample_interval))
    frame_size = width * height * 3
    
    stats = {
        'decode_times': [],      # æ¯ä¸ª batch è§£ç æ—¶é—´
        'wait_times': [],        # ç­‰å¾…å“åº”æ—¶é—´
        'batch_sizes': [],
        'total_decode_time': 0,
        'total_wait_time': 0,
        'total_frames': 0,
    }
    
    select_filter = f"select='not(mod(n\\,{frame_interval}))'"
    cmd = [
        "ffmpeg",
        "-threads", str(decode_threads),
        "-i", video_path,
        "-vf", select_filter,
        "-vsync", "vfr",
        "-f", "rawvideo",
        "-pix_fmt", "rgb24",
        "-loglevel", "error",
        "-"
    ]
    
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, bufsize=frame_size * 4)
    
    pending_requests = {}
    request_counter = 0
    reading_done = False
    current_frame_idx = 0
    
    while not reading_done or pending_requests:
        # å‘é€è¯·æ±‚
        while not reading_done and len(pending_requests) < max_pending:
            decode_start = time.perf_counter()
            
            frames = []
            frame_times = []
            for _ in range(batch_size):
                raw_data = proc.stdout.read(frame_size)
                if len(raw_data) != frame_size:
                    reading_done = True
                    break
                frame = np.frombuffer(raw_data, dtype=np.uint8).reshape((height, width, 3))
                frames.append(frame.copy())
                frame_time = current_frame_idx / fps
                frame_times.append(frame_time)
                current_frame_idx += frame_interval
            
            decode_end = time.perf_counter()
            
            if not frames:
                reading_done = True
                break
            
            decode_time = decode_end - decode_start
            stats['decode_times'].append(decode_time)
            stats['batch_sizes'].append(len(frames))
            stats['total_decode_time'] += decode_time
            stats['total_frames'] += len(frames)
            
            request_id = f"w{worker_id}_r{request_counter}"
            request_counter += 1
            
            detection_queue.put((request_id, frames, frame_times))
            pending_requests[request_id] = time.perf_counter()
        
        # æ¥æ”¶å“åº”
        if pending_requests:
            try:
                timeout = 0.1 if not reading_done else 30.0
                wait_start = time.perf_counter()
                response = response_queue.get(timeout=timeout)
                resp_id, frame_results = response
                
                if resp_id in pending_requests:
                    wait_time = time.perf_counter() - pending_requests[resp_id]
                    stats['wait_times'].append(wait_time)
                    stats['total_wait_time'] += wait_time
                    del pending_requests[resp_id]
            except Empty:
                continue
    
    proc.stdout.close()
    proc.wait()
    
    stats_queue.put((worker_id, stats))


def run_pipeline_simulation(
    video_files: list[Path],
    num_workers: int,
    num_detectors: int,
    sample_interval: float,
    batch_size: int
):
    """
    è¿è¡Œæ¨¡æ‹Ÿçš„ Pipelineï¼Œæ”¶é›†ç»Ÿè®¡æ•°æ®
    """
    print(f"\næ¨¡æ‹Ÿ Pipeline é…ç½®:")
    print(f"  I/O Workers: {num_workers}")
    print(f"  Detectors: {num_detectors}")
    print(f"  Batch Size: {batch_size}")
    print(f"  Sample Interval: {sample_interval}s")
    print(f"  è§†é¢‘æ•°é‡: {len(video_files)}")
    
    detection_queue = mp.Queue()
    response_queues = {i: mp.Queue() for i in range(num_workers)}
    stats_queue = mp.Queue()
    stop_event = mp.Event()
    
    # å¯åŠ¨ Detectors
    detectors = []
    for i in range(num_detectors):
        # åˆ›å»ºä¸€ä¸ªè½¬å‘å“åº”çš„åŒ…è£…
        p = mp.Process(
            target=detector_worker_wrapper,
            args=(detection_queue, response_queues, stats_queue, "yolov8n.pt", stop_event, i)
        )
        p.start()
        detectors.append(p)
    
    # å¯åŠ¨ I/O Workers
    workers = []
    for i, video in enumerate(video_files[:num_workers]):
        p = mp.Process(
            target=io_worker_simulation,
            args=(str(video), detection_queue, response_queues[i], stats_queue, i, sample_interval, batch_size)
        )
        p.start()
        workers.append(p)
    
    # ç­‰å¾… Workers å®Œæˆ
    for w in workers:
        w.join()
    
    # åœæ­¢ Detectors
    for _ in range(num_detectors):
        detection_queue.put(None)
    stop_event.set()
    
    for d in detectors:
        d.join(timeout=5)
    
    # æ”¶é›†ç»Ÿè®¡æ•°æ®
    all_stats = {}
    while not stats_queue.empty():
        try:
            worker_id, stats = stats_queue.get_nowait()
            all_stats[worker_id] = stats
        except Empty:
            break
    
    return all_stats


def detector_worker_wrapper(
    detection_queue: mp.Queue,
    response_queues: dict,
    stats_queue: mp.Queue,
    model_name: str,
    stop_event: mp.Event,
    detector_id: int
):
    """
    Detector Worker åŒ…è£…å™¨
    """
    from ultralytics import YOLO
    
    model = YOLO(model_name)
    
    stats = {
        'batch_inference_times': [],
        'batch_sizes': [],
        'queue_wait_times': [],
        'total_processed': 0,
    }
    
    while not stop_event.is_set():
        wait_start = time.perf_counter()
        try:
            request = detection_queue.get(timeout=0.5)
        except Empty:
            continue
        wait_end = time.perf_counter()
        
        if request is None:
            detection_queue.put(None)  # ä¼ é€’ç»™å…¶ä»– detector
            break
        
        request_id, worker_id, frames, frame_times = request
        stats['queue_wait_times'].append(wait_end - wait_start)
        
        if frames:
            infer_start = time.perf_counter()
            results = model(frames, verbose=False, conf=0.5, classes=[0])
            infer_end = time.perf_counter()
            
            stats['batch_inference_times'].append(infer_end - infer_start)
            stats['batch_sizes'].append(len(frames))
            stats['total_processed'] += len(frames)
            
            frame_results = [(frame_times[i], len(results[i].boxes)) for i in range(len(results))]
            if worker_id in response_queues:
                response_queues[worker_id].put((request_id, frame_results))
        else:
            if worker_id in response_queues:
                response_queues[worker_id].put((request_id, []))
    
    stats_queue.put((f"detector_{detector_id}", stats))


def analyze_single_video_timing(video_path: str, sample_interval: float, batch_size: int):
    """
    åˆ†æå•ä¸ªè§†é¢‘å¤„ç†çš„æ—¶åº
    """
    print(f"\nåˆ†æè§†é¢‘: {Path(video_path).name}")
    
    timings = simulate_io_worker_timing(video_path, sample_interval, batch_size)
    
    if 'error' in timings:
        print(f"  é”™è¯¯: {timings['error']}")
        return
    
    batch_read_times = timings['batch_read_times']
    batch_sizes = timings['batch_sizes']
    
    print(f"\n  è§†é¢‘æ—¶é•¿: {timings['video_duration']:.1f}s")
    print(f"  æ€»å¸§æ•°: {timings['total_frames']}")
    print(f"  Batch æ•°: {timings['batch_count']}")
    
    if batch_read_times:
        avg_read_time = np.mean(batch_read_times)
        avg_batch_size = np.mean(batch_sizes)
        
        print(f"\n  æ¯ Batch å¹³å‡è¯»å–æ—¶é—´: {avg_read_time*1000:.1f} ms")
        print(f"  æ¯ Batch å¹³å‡å¸§æ•°: {avg_batch_size:.1f}")
        print(f"  è§£ç é€Ÿç‡: {avg_batch_size / avg_read_time:.1f} fps")
        
        # ä¼°ç®—æ¨ç†æ—¶é—´
        # æ ¹æ®ä¹‹å‰æµ‹è¯•ï¼ŒYOLO å¤§çº¦ 17 fps = 58ms/frame
        estimated_infer_time = avg_batch_size * 0.058
        
        print(f"\n  ğŸ“Š æ—¶é—´åˆ†é…ä¼°ç®— (æ¯ batch):")
        print(f"     è§£ç æ—¶é—´: {avg_read_time*1000:.1f} ms")
        print(f"     æ¨ç†æ—¶é—´ (ä¼°): {estimated_infer_time*1000:.1f} ms")
        print(f"     æ€»æ—¶é—´: {(avg_read_time + estimated_infer_time)*1000:.1f} ms")
        
        if avg_read_time > estimated_infer_time:
            print(f"\n  âš ï¸ ç“¶é¢ˆ: è§£ç  (å  {avg_read_time/(avg_read_time+estimated_infer_time)*100:.0f}%)")
        else:
            print(f"\n  âš ï¸ ç“¶é¢ˆ: æ¨ç† (å  {estimated_infer_time/(avg_read_time+estimated_infer_time)*100:.0f}%)")


def main():
    parser = argparse.ArgumentParser(description="Pipeline å¤šè¿›ç¨‹æ€§èƒ½åˆ†æ")
    parser.add_argument("input", help="è¾“å…¥è§†é¢‘ç›®å½•")
    parser.add_argument("--interval", type=float, default=3.0, help="é‡‡æ ·é—´éš”ï¼ˆç§’ï¼‰")
    parser.add_argument("--batch-size", type=int, default=32, help="Batch å¤§å°")
    args = parser.parse_args()
    
    if os.name != 'nt':
        mp.set_start_method('spawn', force=True)
    
    videos = get_video_files(args.input)
    
    if not videos:
        print(f"æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {args.input}")
        return
    
    print(f"æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘æ–‡ä»¶")
    
    # 1. åˆ†æå•è§†é¢‘æ—¶åº
    print("\n" + "="*60)
    print("1. å•è§†é¢‘æ—¶åºåˆ†æ")
    print("="*60)
    
    for video in videos[:3]:
        analyze_single_video_timing(str(video), args.interval, args.batch_size)
    
    # 2. åˆ†æå¤šè¿›ç¨‹ Pipeline
    print("\n" + "="*60)
    print("2. å¤šè¿›ç¨‹ Pipeline æ—¶åºåˆ†æ")
    print("="*60)
    
    # ä½¿ç”¨ 2 ä¸ª worker å’Œ 2 ä¸ª detector åšç®€å•æµ‹è¯•
    print("\nè¿è¡Œç®€åŒ–çš„ Pipeline æ¨¡æ‹Ÿ...")
    
    # è¿™é‡Œæˆ‘ä»¬æ‰‹åŠ¨æµ‹è¯•ä¸€ä¸‹å•ä¸ª worker + å•ä¸ª detector çš„æƒ…å†µ
    print("\næµ‹è¯•å• Worker + å• Detector é…ç½®...")
    
    detection_queue = mp.Queue()
    response_queue = mp.Queue()
    stats_queue = mp.Queue()
    stop_event = mp.Event()
    
    # å¯åŠ¨ Detector
    detector = mp.Process(
        target=simple_detector_worker,
        args=(detection_queue, response_queue, stats_queue, "yolov8n.pt", stop_event, 0)
    )
    detector.start()
    
    # æ¨¡æ‹Ÿ I/O Worker
    video = videos[0]
    worker_stats = simple_io_worker(
        str(video),
        detection_queue,
        response_queue,
        args.interval,
        args.batch_size
    )
    
    # åœæ­¢ Detector
    detection_queue.put(None)
    detector.join(timeout=10)
    
    # è·å– Detector ç»Ÿè®¡
    detector_stats = {}
    try:
        while not stats_queue.empty():
            det_id, stats = stats_queue.get_nowait()
            detector_stats[det_id] = stats
    except:
        pass
    
    # åˆ†æç»“æœ
    print(f"\nğŸ“Š I/O Worker ç»Ÿè®¡:")
    print(f"   æ€»å¸§æ•°: {worker_stats['total_frames']}")
    print(f"   æ€»è§£ç æ—¶é—´: {worker_stats['total_decode_time']:.2f}s")
    print(f"   æ€»ç­‰å¾…å“åº”æ—¶é—´: {worker_stats['total_wait_time']:.2f}s")
    print(f"   è§£ç æ—¶é—´å æ¯”: {worker_stats['total_decode_time'] / (worker_stats['total_decode_time'] + worker_stats['total_wait_time']) * 100:.1f}%")
    print(f"   ç­‰å¾…æ—¶é—´å æ¯”: {worker_stats['total_wait_time'] / (worker_stats['total_decode_time'] + worker_stats['total_wait_time']) * 100:.1f}%")
    
    if worker_stats['wait_times']:
        print(f"\n   æ¯ Batch ç­‰å¾…æ—¶é—´:")
        print(f"     å¹³å‡: {np.mean(worker_stats['wait_times'])*1000:.1f} ms")
        print(f"     æœ€å¤§: {np.max(worker_stats['wait_times'])*1000:.1f} ms")
        print(f"     æœ€å°: {np.min(worker_stats['wait_times'])*1000:.1f} ms")
    
    if 0 in detector_stats:
        det_stats = detector_stats[0]
        print(f"\nğŸ“Š Detector ç»Ÿè®¡:")
        print(f"   æ€»å¤„ç†å¸§æ•°: {det_stats['total_processed']}")
        if det_stats['batch_inference_times']:
            print(f"   æ¯ Batch æ¨ç†æ—¶é—´:")
            print(f"     å¹³å‡: {np.mean(det_stats['batch_inference_times'])*1000:.1f} ms")
            print(f"     æ¯å¸§: {np.mean(det_stats['batch_inference_times']) / np.mean(det_stats['batch_sizes']) * 1000:.1f} ms")
    
    print("\n" + "="*60)
    print("ğŸ” ç“¶é¢ˆæ€»ç»“")
    print("="*60)
    
    decode_ratio = worker_stats['total_decode_time'] / (worker_stats['total_decode_time'] + worker_stats['total_wait_time'])
    wait_ratio = worker_stats['total_wait_time'] / (worker_stats['total_decode_time'] + worker_stats['total_wait_time'])
    
    if decode_ratio > 0.6:
        print(f"\nâš ï¸  ä¸»è¦ç“¶é¢ˆ: FFmpeg è§£ç  ({decode_ratio*100:.0f}%)")
        print("   åŸå› : è§£ç  2304x1296 é«˜åˆ†è¾¨ç‡è§†é¢‘éœ€è¦å¤§é‡ CPU")
        print("   å»ºè®®:")
        print("   1. å‡å°‘ I/O Worker æ•°é‡ï¼Œæ¯ä¸ª Worker åˆ†é…æ›´å¤š CPU èµ„æº")
        print("   2. å¢åŠ  ffmpeg decode_threads")
        print("   3. ä½¿ç”¨æ›´ä½åˆ†è¾¨ç‡çš„è§†é¢‘æº")
    elif wait_ratio > 0.6:
        print(f"\nâš ï¸  ä¸»è¦ç“¶é¢ˆ: Detector æ¨ç† ({wait_ratio*100:.0f}%)")
        print("   åŸå› : YOLO æ¨ç†é€Ÿåº¦é™åˆ¶äº†æ•´ä½“åå")
        print("   å»ºè®®:")
        print("   1. å¢åŠ  Detector Worker æ•°é‡")
        print("   2. ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ (å¦‚ yolov8n)")
        print("   3. ä½¿ç”¨ GPU åŠ é€Ÿ")
    else:
        print(f"\nè§£ç å’Œæ¨ç†æ—¶é—´ç›¸è¿‘:")
        print(f"   è§£ç : {decode_ratio*100:.0f}%")
        print(f"   æ¨ç†: {wait_ratio*100:.0f}%")
        print("   éœ€è¦åŒæ—¶ä¼˜åŒ–ä¸¤ä¸ªç¯èŠ‚")


def simple_detector_worker(
    detection_queue: mp.Queue,
    response_queue: mp.Queue,
    stats_queue: mp.Queue,
    model_name: str,
    stop_event: mp.Event,
    detector_id: int
):
    """ç®€åŒ–ç‰ˆ Detector Worker"""
    from ultralytics import YOLO
    
    model = YOLO(model_name)
    
    stats = {
        'batch_inference_times': [],
        'batch_sizes': [],
        'total_processed': 0,
    }
    
    while True:
        try:
            request = detection_queue.get(timeout=1.0)
        except Empty:
            if stop_event.is_set():
                break
            continue
        
        if request is None:
            break
        
        request_id, frames, frame_times = request
        
        if frames:
            infer_start = time.perf_counter()
            results = model(frames, verbose=False, conf=0.5, classes=[0])
            infer_end = time.perf_counter()
            
            stats['batch_inference_times'].append(infer_end - infer_start)
            stats['batch_sizes'].append(len(frames))
            stats['total_processed'] += len(frames)
            
            frame_results = [(frame_times[i], len(results[i].boxes)) for i in range(len(results))]
            response_queue.put((request_id, frame_results))
        else:
            response_queue.put((request_id, []))
    
    stats_queue.put((detector_id, stats))


def simple_io_worker(
    video_path: str,
    detection_queue: mp.Queue,
    response_queue: mp.Queue,
    sample_interval: float,
    batch_size: int,
    decode_threads: int = 2
) -> dict:
    """ç®€åŒ–ç‰ˆ I/O Workerï¼Œè¿”å›ç»Ÿè®¡æ•°æ®"""
    info = probe_video_info(video_path)
    if not info:
        return {'error': 'Cannot probe video'}
    
    fps = info['fps']
    width = info['width']
    height = info['height']
    frame_interval = max(1, int(fps * sample_interval))
    frame_size = width * height * 3
    
    stats = {
        'decode_times': [],
        'wait_times': [],
        'batch_sizes': [],
        'total_decode_time': 0,
        'total_wait_time': 0,
        'total_frames': 0,
    }
    
    select_filter = f"select='not(mod(n\\,{frame_interval}))'"
    cmd = [
        "ffmpeg",
        "-threads", str(decode_threads),
        "-i", video_path,
        "-vf", select_filter,
        "-vsync", "vfr",
        "-f", "rawvideo",
        "-pix_fmt", "rgb24",
        "-loglevel", "error",
        "-"
    ]
    
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, bufsize=frame_size * 4)
    
    pending_requests = {}
    request_counter = 0
    reading_done = False
    current_frame_idx = 0
    max_pending = 8
    
    while not reading_done or pending_requests:
        # å‘é€è¯·æ±‚ï¼ˆé¢„å–ï¼‰
        while not reading_done and len(pending_requests) < max_pending:
            decode_start = time.perf_counter()
            
            frames = []
            frame_times = []
            for _ in range(batch_size):
                raw_data = proc.stdout.read(frame_size)
                if len(raw_data) != frame_size:
                    reading_done = True
                    break
                frame = np.frombuffer(raw_data, dtype=np.uint8).reshape((height, width, 3))
                frames.append(frame.copy())
                frame_time = current_frame_idx / fps
                frame_times.append(frame_time)
                current_frame_idx += frame_interval
            
            decode_end = time.perf_counter()
            
            if not frames:
                reading_done = True
                break
            
            decode_time = decode_end - decode_start
            stats['decode_times'].append(decode_time)
            stats['batch_sizes'].append(len(frames))
            stats['total_decode_time'] += decode_time
            stats['total_frames'] += len(frames)
            
            request_id = f"r{request_counter}"
            request_counter += 1
            
            detection_queue.put((request_id, frames, frame_times))
            pending_requests[request_id] = time.perf_counter()
        
        # æ¥æ”¶å“åº”
        if pending_requests:
            try:
                timeout = 0.1 if not reading_done else 30.0
                response = response_queue.get(timeout=timeout)
                resp_id, _ = response
                
                if resp_id in pending_requests:
                    wait_time = time.perf_counter() - pending_requests[resp_id]
                    stats['wait_times'].append(wait_time)
                    stats['total_wait_time'] += wait_time
                    del pending_requests[resp_id]
            except Empty:
                continue
    
    proc.stdout.close()
    proc.wait()
    
    return stats


if __name__ == "__main__":
    main()
